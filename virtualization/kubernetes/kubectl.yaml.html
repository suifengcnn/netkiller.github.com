<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>2.7. Kubectl YAML</title><link rel="stylesheet" type="text/css" href="..//docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="qmeu,kvm,xen,openvz, docker, coreos, , " /><link rel="home" href="../index.html" title="Netkiller Virtualization 手札" /><link rel="up" href="index.html" title="第 2 章 Kubernetes" /><link rel="prev" href="kubectl.example.html" title="2.6. kubectl example" /><link rel="next" href="istio.html" title="2.8. istio" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> |
		<a xmlns="" href="//netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="/journal/index.html">杂文</a> |
	    <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> |
	    <a xmlns="" href="https://github.com/netkiller">Github</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://cloud.tencent.com/developer/column/2078">云社区</a> |
	    <a xmlns="" href="https://yq.aliyun.com/u/netkiller/">云栖社区</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/video.html">视频教程</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">2.7. Kubectl YAML</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="kubectl.example.html">上一页</a> </td><th width="60%" align="center">第 2 章 Kubernetes</th><td width="20%" align="right"> <a accesskey="n" href="istio.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> ｜ <a href="https://www.zhihu.com/club/1241768772601950208">多维度架构</a></td><td> 微信号 netkiller-ebook | QQ群：128659835 请注明“读者” </td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="kubectl.yaml"></a>2.7. Kubectl YAML</h2></div></div></div>
	
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="ServiceAccount"></a>2.7.1. ServiceAccount</h3></div></div></div>
		
		<pre class="screen">
		
apiVersion: v1
kind: ServiceAccount
metadata:
 labels:
   app: elasticsearch
 name: elasticsearch
 namespace: elastic		
		
		</pre>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp208"></a>2.7.1.1. </h4></div></div></div>
			
		</div>
	</div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Namespace"></a>2.7.2. 创建命名空间</h3></div></div></div>
		
		<p> 创建 jenkins-namespace.yaml</p>
		<pre class="screen">
			
apiVersion: v1
kind: Namespace
metadata:
  name: jenkins-project
			
		</pre>
		<pre class="screen">
			
$ kubectl create -f jenkins-namespace.yaml
namespace ”jenkins-project“ created			
			
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Pod"></a>2.7.3. Pod</h3></div></div></div>
		
		<pre class="screen">
		
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c, 'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']		
		
		</pre>
		<p></p>
		<pre class="screen">
		
iMac:kubernetes neo$ kubectl create -f pod.yaml 
pod/counter created

iMac:kubernetes neo$ kubectl logs counter
0: Sun Oct  4 12:32:44 UTC 2020
1: Sun Oct  4 12:32:45 UTC 2020
2: Sun Oct  4 12:32:46 UTC 2020
3: Sun Oct  4 12:32:47 UTC 2020
4: Sun Oct  4 12:32:48 UTC 2020
5: Sun Oct  4 12:32:49 UTC 2020
6: Sun Oct  4 12:32:50 UTC 2020
7: Sun Oct  4 12:32:51 UTC 2020
8: Sun Oct  4 12:32:52 UTC 2020
9: Sun Oct  4 12:32:53 UTC 2020
		
		</pre>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp209"></a>2.7.3.1. 指定主机名</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: hostaliases-pod
spec:
  restartPolicy: Never
  hostAliases:
  - ip: "127.0.0.1"
    hostnames:
    - "foo.local"
    - "bar.local"
  - ip: "10.1.2.3"
    hostnames:
    - "foo.remote"
    - "bar.remote"
  containers:
  - name: cat-hosts
    image: busybox
    command:
    - cat
    args:
    - "/etc/hosts"			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp210"></a>2.7.3.2. </h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: envars-fieldref
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ "sh", "-c"]
      args:
      - while true; do
          echo -en '\n';
          printenv NODE_NAME POD_NAME POD_NAMESPACE;
          printenv POD_IP POD_SERVICE_ACCOUNT;
          sleep 10;
        done;
      env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: POD_SERVICE_ACCOUNT
          valueFrom:
            fieldRef:
              fieldPath: spec.serviceAccountName
  restartPolicy: Never			
			
			</pre>
			<p></p>
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: envars-resourcefieldref
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox:1.24
      command: [ "sh", "-c"]
      args:
      - while true; do
          echo -en '\n';
          printenv CPU_REQUEST CPU_LIMIT;
          printenv MEM_REQUEST MEM_LIMIT;
          sleep 10;
        done;
      resources:
        requests:
          memory: "32Mi"
          cpu: "125m"
        limits:
          memory: "64Mi"
          cpu: "250m"
      env:
        - name: CPU_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: requests.cpu
        - name: CPU_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: limits.cpu
        - name: MEM_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: requests.memory
        - name: MEM_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: limits.memory
  restartPolicy: Never			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp211"></a>2.7.3.3. 健康状态检查</h4></div></div></div>
			
			<p>就绪探针</p>
			<pre class="screen">
			
        readinessProbe: 
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 10         #10s之后开始第一次探测
          periodSeconds: 5                #第一次探测之后每隔5s探测一次			
			
			</pre>
			<p></p>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="securityContext"></a>2.7.3.4. securityContext</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp212"></a>2.7.3.4.1. sysctls</h5></div></div></div>
				
				<p></p>
				<pre class="screen">
				
kubelet --allowed-unsafe-sysctls \
  'kernel.msg*,net.core.somaxconn' ...				
				
				</pre>
				<pre class="screen">
				
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
spec:
  securityContext:
    sysctls:
    - name: kernel.shm_rmid_forced
      value: "0"
    - name: net.core.somaxconn
      value: "1024"
    - name: kernel.msgmax
      value: "65536"				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp213"></a>2.7.3.4.2. runAsUser</h5></div></div></div>
				
				<p>allowPrivilegeEscalation 表示是否继承父进程权限，runAsUser 表示使用 UID 1000 的用户运行</p>
				<pre class="screen">
				
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000
  containers:
  - name: sec-ctx-demo
    image: busybox:latest
    securityContext:
      runAsUser: 1000
      allowPrivilegeEscalation: false				
				
				</pre>
				<pre class="screen">
				
   spec:
     securityContext:
        runAsUser: 1000
        fsGroup: 2000
        runAsNonRoot: true				
				
				</pre>
			</div>

			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp214"></a>2.7.3.4.3. security.alpha.kubernetes.io/sysctls</h5></div></div></div>
				
				<p>security.alpha.kubernetes.io/sysctls</p>
				<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
  annotations:
    security.alpha.kubernetes.io/sysctls: kernel.shm_rmid_forced=1
spec:			
			
				</pre>
				<p>unsafe-sysctls</p>
				<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
  annotations:
    security.alpha.kubernetes.io/unsafe-sysctls: net.core.somaxconn=65535                 #使用unsafe sysctl，设置最大连接数
spec:
  securityContext:
    privileged: true                                                                      #开启privileged权限			
			
				</pre>
			</div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp215"></a>2.7.3.5. Taint（污点）和 Toleration（容忍）</h4></div></div></div>
			
			<pre class="screen">
			
			
			
			</pre>
		</div>
		
	</div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Service"></a>2.7.4. Service</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp216"></a>2.7.4.1. 创建服务</h4></div></div></div>
			
			<p>创建 service.yaml 文件</p>
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
  - name: https
    protocol: TCP
    port: 443
    targetPort: 443
			
			</pre>
			<p></p>
			<pre class="screen">
			
iMac:kubernetes neo$ kubectl create -f service.yaml 
service/my-service created			
			
			</pre>
			<p>查看服务</p>
			<pre class="screen">
			
iMac:kubernetes neo$ kubectl get service
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP          113m
my-service   ClusterIP   10.106.157.143   &lt;none&gt;        80/TCP,443/TCP   64s			
			
			</pre>
			<p>查看 service 后端代理的 pod 的 ip，这里没有挂载 pod 所以显示 none</p>
			<pre class="screen">
			
iMac:kubernetes neo$ kubectl get endpoints my-service
NAME         ENDPOINTS   AGE
my-service   &lt;none&gt;      2m20s			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp217"></a>2.7.4.2. 查看服务</h4></div></div></div>
			

		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp218"></a>2.7.4.3. 设置外部IP</h4></div></div></div>
			
			<p>报漏 80.11.12.10:80 地址</p>
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
  externalIPs:
    - 80.11.12.10			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp219"></a>2.7.4.4. 绑定外部域名</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp220"></a>2.7.4.5. </h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: spring-cloud-config-server
  namespace: default
  labels:
    app: springboot
spec:
  #type: NodePort
  ports: web
  - port: 8888
    targetPort: web
  clusterIP: 10.10.0.1
  selector:
    app: spring-cloud-config-server
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp221"></a>2.7.4.6. nodePort</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: MyApp
  ports:
      # By default and for convenience, the `targetPort` is set to the same value as the `port` field.
    - port: 80
      targetPort: 80
      # Optional field
      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
      nodePort: 30007			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp222"></a>2.7.4.7. LoadBalancer</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  clusterIP: 10.0.171.239
  type: LoadBalancer
status:
  loadBalancer:
    ingress:
    - ip: 192.0.2.127			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp223"></a>2.7.4.8. Example</h4></div></div></div>
			
			<pre class="screen">
		
apiVersion: v1
kind: Service
metadata:
  name: registry
  namespace: default
  labels:
    app: registry
spec:
  type: NodePort
  selector:
    app: registry
  ports:
  - name: registry
    port: 5000
    nodePort: 30050
    protocol: TCP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: registry
  namespace: default
  labels:
    app: registry
spec:
  replicas: 1
  selector:
    matchLabels:
      app: registry
  template:
    metadata:
      labels:
        app: registry
    spec:
      containers:
      - name: registry
        image: registry:latest
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        env:
        - name: REGISTRY_HTTP_ADDR
          value: :5000
        - name: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY
          value: /var/lib/registry
        ports:
        - containerPort: 5000
          name: registry
          protocol: TCP	
		
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="ConfigMap"></a>2.7.5. ConfigMap</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp224"></a>2.7.5.1. Key-Value 配置</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-config
  namespace: default
data:
  db.host: 172.16.0.10
  db.port: '3306'
  db.user: neo
  db.pass: chen
			
			</pre>
			<p>创建配置</p>
			<pre class="screen">
			
neo@MacBook-Pro-Neo ~/tmp/kubernetes % kubectl create -f key-value.yaml
configmap/db-config created
			
			</pre>
			<p>将配置项保存到文件</p>
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh", "-c", "cat /usr/local/etc/config/db.host" ]
      volumeMounts:
      - name: config-volume
        mountPath: /usr/local/etc/config
  volumes:
    - name: config-volume
      configMap:
        name: db-config
  restartPolicy: Never			
			
			</pre>
			<p>定义多组配置项</p>
			<pre class="screen">
			
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-cloud-config
  namespace: default
data:
  config: |
    spring.security.user=config
    spring.security.user=passw0rd
  euerka: |
    spring.security.user=eureka
    spring.security.user=passw0rd
  gateway: |
    spring.security.user=gateway
    spring.security.user=passw0rd    
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp225"></a>2.7.5.2. 环境变量</h4></div></div></div>
			
			<p>envFrom 可将 ConfigMap 中的配置项定义为容器环境变量</p>
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: neo-test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ "/bin/sh", "-c", "env" ]
      envFrom:
      - configMapRef:
          name: special-config
  restartPolicy: Never			
			
			</pre>
			<p>引用单个配置项使用 valueFrom</p>
			<pre class="screen">
			
neo@MacBook-Pro-Neo ~/tmp/kubernetes % cat key-value.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-config
  namespace: default
data:
  db.host: 172.16.0.10
  db.port: '3306'		
  db.user: neo
  db.pass: chen
---
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
    - name: test-container
      image: busybox
      command: [ "/bin/sh", "-c", "env" ]
      env:
        - name: DBHOST
          valueFrom:
            configMapKeyRef:
              name: db-config
              key: db.host
        - name: DBPORT
          valueFrom:
            configMapKeyRef:
              name: db-config
              key: db.port
  restartPolicy: Never				
			
neo@MacBook-Pro-Neo ~/tmp/kubernetes % kubectl create -f key-value.yaml
configmap/db-config created
pod/test-pod created		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp226"></a>2.7.5.3. 配置文件</h4></div></div></div>
			
			<p>定义配置</p>
			<pre class="screen">
		
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  labels:
    app: redis
data:
  redis.conf: |-
    pidfile /var/lib/redis/redis.pid
    dir /var/lib/redis
    port 6379
    bind 0.0.0.0
    appendonly yes
    protected-mode no
    requirepass 123456
		
			</pre>
			<p>引用配置</p>
			<pre class="screen">
		
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  labels:
    app: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:5.0.8
        command: 
          - "sh"
          - "-c"
          - "redis-server /usr/local/etc/redis/redis.conf"
        ports:
        - containerPort: 6379
        resources:
          limits:
            cpu: 1000m
            memory: 1024Mi
          requests:
            cpu: 1000m
            memory: 1024Mi
        livenessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 300
          timeoutSeconds: 1
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 5
          timeoutSeconds: 1
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config
          mountPath:  /usr/local/etc/redis/redis.conf
          subPath: redis.conf
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: redis
      - name: config
        configMap:
          name: redis-config
		
			</pre>
			<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh","-c","find /etc/config/" ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: special-config
        items:
        - key: special.how
          path: path/to/special-key
  restartPolicy: Never			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Volume"></a>2.7.6. Volume</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp228"></a>2.7.6.1. local</h4></div></div></div>
			
			<pre class="screen">
			
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-pv
spec:
  capacity:
    storage: 100Gi
  # volumeMode field requires BlockVolume Alpha feature gate to be enabled.
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /mnt/disks/ssd1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - example-node			
			
			</pre>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp227"></a>2.7.6.1.1. 案例</h5></div></div></div>
				
				<pre class="screen">
				
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-volume
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: netkiller-local-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-volume
  local:
    path: /tmp/neo
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - minikube
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: netkiller-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-volume
---
kind: Pod
apiVersion: v1
metadata:
  name: busybox
  namespace: default
spec:
  containers:
    - name: busybox
      image: busybox:latest
      # image: registry.netkiller.cn:5000/netkiller/welcome:latest
      imagePullPolicy: IfNotPresent
      command:
        - sleep
        - "3600"
      volumeMounts:
      - mountPath: "/srv"
        name: mypd
  restartPolicy: Always
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: netkiller-pvc			
				
				</pre>
				<p>部署 POD</p>
				<pre class="screen">
				
iMac:kubernetes neo$ kubectl create -f example/volume/local.yaml 
storageclass.storage.k8s.io/local-volume created
persistentvolume/netkiller-local-pv created
persistentvolumeclaim/netkiller-pvc created
pod/busybox created				
				
				</pre>
				<p>查看POD状态</p>
				<pre class="screen">
				
iMac:kubernetes neo$ kubectl get pod
NAME      READY   STATUS    RESTARTS   AGE
busybox   1/1     Running   0          2m28s				
				
				</pre>
				<p>进入POD查看local卷的挂载情况，同时创建一个测试文件。</p>
				<pre class="screen">
				
iMac:kubernetes neo$ kubectl exec -it busybox sh
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
/ # mount | grep /srv
tmpfs on /srv type tmpfs (rw)

/ # echo helloworld &gt; /srv/netkiller
/ # cat /srv/netkiller 
helloworld
				
				</pre>
				<p>进入宿主主机查看挂载目录</p>
				<pre class="screen">
				
$ cat /tmp/neo/netkiller 
helloworld
				
				</pre>
			</div>
		</div>
	</div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Job"></a>2.7.7. Job</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp229"></a>2.7.7.1. 执行单词任务</h4></div></div></div>
			
			<p>.spec.completions 标志Job结束需要成功运行的Pod个数，默认为1</p>
			<p>.spec.parallelism 标志并行运行的Pod的个数，默认为1</p>
			<p>.spec.activeDeadlineSeconds 标志失败Pod的重试最大时间，超过这个时间不会继续重试</p>
			<pre class="screen">
			
apiVersion: batch/v1
kind: Job
metadata:
  name: busybox
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      name: busybox
    spec:
      containers:
      - name: busybox
        image: busybox
        command: ["echo", "hello"]
      restartPolicy: Never			
			
			</pre>
			<p></p>
			<pre class="screen">
			
$ kubectl create -f job.yaml
job "busybox" created
$ pods=$(kubectl get pods --selector=job-name=busybox --output=jsonpath={.items..metadata.name})
$ kubectl logs $pods		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp230"></a>2.7.7.2. 计划任务</h4></div></div></div>
			
			<p>.spec.schedule 指定任务运行周期，格式同Cron</p>
			<p>.spec.startingDeadlineSeconds 指定任务开始的截止期限</p>
			<p>.spec.concurrencyPolicy 指定任务的并发策略，支持Allow、Forbid和Replace三个选项</p>
			<pre class="screen">
			
apiVersion: batch/v2alpha1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="Ingress"></a>2.7.8. Ingress</h3></div></div></div>
		
		<p>正常情况 Service 只是暴露了端口，这个端口是可以对外访问的，但是80端口只有一个，很多 Service 都要使用 80端口，这时就需要使用虚拟主机技术。</p>
		<p>多个 Service 共同使用一个 80 端口，通过域名区分业务。这就是 Ingress 存在的意义。</p>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp231"></a>2.7.8.1. 端口</h4></div></div></div>
			
			<pre class="screen">
			
+----------+  Ingress   +---------+    Pod    +----------+
| internet | ---------&gt; | Service | --------&gt; | Pod Node |
+----------+            +---------+           +----------+
			
			
			</pre>
			<pre class="screen">
			
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: springboot
spec:
  backend:
    service:
      name: springboot
      port: 
        number: 80			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp232"></a>2.7.8.2. URI 规则</h4></div></div></div>
			
			<pre class="screen">
			
                  Ingress	 / ---&gt; /api --&gt; api-service:8080		
www.netkiller.cn ---------&gt; |  ---&gt; /usr --&gt; usr-service:8080
                             \ ---&gt; /img --&gt; img-service:8080			
			
			</pre>
			<pre class="screen">
			
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: uri-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: www.netkiller.cn
    http:
      paths:
      - path: /api
        backend:
          serviceName: api-service
          servicePort: 8080
      - path: /usr
        backend:
          serviceName: usr-service
          servicePort: 8080		
      - path: /img
        backend:
          serviceName: img-service
          servicePort: 8080		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp233"></a>2.7.8.3. vhost 虚拟主机</h4></div></div></div>
			
			<pre class="screen">
			
www.netkiller.cn --|     Ingress     |-&gt; www.netkiller.cn www:80
                   | --------------&gt; |
img.netkiller.cn --|                 |-&gt; img.netkiller.cn img:80			
			
			</pre>
			<pre class="screen">
			
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: vhost-ingress
spec:
  rules:
  - host: www.netkiller.cn
    http:
      paths:
      - backend:
          serviceName: www
          servicePort: 80
  - host: img.netkiller.cn
    http:
      paths:
      - backend:
          serviceName: img
          servicePort: 80			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp234"></a>2.7.8.4. rewrite</h4></div></div></div>
			
			<pre class="screen">
			
http://www.netkiller.cn/1100 =&gt; /article/1100			
			
			</pre>
			<pre class="screen">
			
apiVersion: networking.k8s.io/v1beta1
kind: Ingress			
metadata:
  name: rewrite-ingress
  annotations: 
    nginx.ingress.kubernetes.io/rewrite-target: /article/$1
spec:
  rules:
  - host: www.netkiller.cn
    http:
      paths:
        # 可以有多个（可以正则）
        - path: /($/.*)
          backend:
            serviceName: article
            servicePort: 80	
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp237"></a>2.7.8.5. annotations 配置</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp235"></a>2.7.8.5.1. HTTP 跳转到 HTTPS</h5></div></div></div>
				
				<pre class="screen">
				
# 该注解只在配置了HTTPS之后才会生效进行跳转
nginx.ingress.kubernetes.io/ssl-redirect: "true"

# 强制跳转到https，不论是否配置了https证书
nginx.ingress.kubernetes.io/force-ssl-redirect: "true"				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp236"></a>2.7.8.5.2. server-snippet</h5></div></div></div>
				
				<p>server-snippet 可以让你直接编排 Nginx 配置</p>
				<pre class="screen">
				
nginx.ingress.kubernetes.io/server-snippet: |
    rewrite /api/($|.*) /api/v2/$1 break;
    rewrite /img/($|.*) /img/thumbnail/$1 break;
				
				</pre>
			</div>

		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp242"></a>2.7.8.6. 金丝雀发布（灰度发布）</h4></div></div></div>
			
			<p>三种annotation按匹配优先级顺序：</p>
			<pre class="screen">
			
canary-by-header &gt; canary-by-cookie &gt; canary-weight			
			
			</pre>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp238"></a>2.7.8.6.1. 准备服务</h5></div></div></div>
				
				<pre class="screen">
				
# Release Version
apiVersion: v1
kind: Service
metadata:
    name: hello-service
    labels:
    app: hello-service
spec:
ports:
- port: 80
    protocol: TCP
selector:
    app: hello-service
---
# canary Version
apiVersion: v1
kind: Service
metadata:
    name: canary-hello-service
    labels:
    app: canary-hello-service
spec:
ports:
- port: 80
    protocol: TCP
selector:
    app: canary-hello-service				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp239"></a>2.7.8.6.2. 方案一，权重分配</h5></div></div></div>
				
				<pre class="screen">
				
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: canary
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "30"
spec:
  rules:
  - host: canary.netkiller.cn
    http:
      paths:
      - backend:
          serviceName: canary-hello-service 
				
				</pre>
				<p></p>
				<pre class="screen">
				
$ for i in $(seq 1 10); do curl http://canary.netkiller.cn; echo '\n'; done				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp240"></a>2.7.8.6.3. 通过HTTP头开启灰度发布</h5></div></div></div>
				
				<pre class="screen">
				
annotations:
  kubernetes.io/ingress.class: nginx
  nginx.ingress.kubernetes.io/canary: "true"
  nginx.ingress.kubernetes.io/canary-by-header: "canary"				
				
				</pre>
				<p></p>
				<pre class="screen">
				
$ for i in $(seq 1 5); do curl -H 'canary:always' http://canary.netkiller.cn; echo '\n'; done				
				
				</pre>
				<p></p>
				<pre class="screen">
				
annotations:
  kubernetes.io/ingress.class: nginx
  nginx.ingress.kubernetes.io/canary: "true"
  nginx.ingress.kubernetes.io/canary-by-header: "canary"
  nginx.ingress.kubernetes.io/canary-by-header-value: "true"				
				
				</pre>
				<p></p>
				<pre class="screen">
				
$ for i in $(seq 1 5); do curl -H 'canary:true' http://canary.netkiller.cn; echo '\n'; done						
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idp241"></a>2.7.8.6.4. 通过 Cookie 开启</h5></div></div></div>
				
				<pre class="screen">
				
annotations:
  kubernetes.io/ingress.class: nginx
  nginx.ingress.kubernetes.io/canary: "true"
  nginx.ingress.kubernetes.io/canary-by-cookie: "canary"				
				
				</pre>
				<p></p>
				<pre class="screen">
				
$ for i in $(seq 1 5); do curl -b 'canary=always' http://canary.netkiller.cn; echo '\n'; done				
				
				</pre>
			</div>
		</div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp243"></a>2.7.8.7. 管理 Ingress</h4></div></div></div>
			
			<pre class="screen">
			
# 查看已有配置
kubectl describe ingress test

# 修改配置
kubectl edit ingress test	

# 来重新载入配置
kubectl replace -f ingress.yaml		
			
			</pre>
		</div>
	</div>
</div><div xmlns="" id="disqus_thread"></div><script xmlns="">

var disqus_config = function () {
this.page.url = "http://www.netkiller.cn";  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'netkiller'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//netkiller.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script><noscript xmlns="">Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><br xmlns="" /><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="kubectl.example.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="istio.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">2.6. kubectl example </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 2.8. istio</td></tr></table></div><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11694057-1', 'auto');
  ga('send', 'pageview');

</script><script xmlns="" async="async">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script xmlns="" async="async">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script></body></html>