<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Glusterfs</title><link rel="stylesheet" type="text/css" href="docbook.css"/><link rel="stylesheet" type="text/css" href="/journal/journal.css"/><meta name="generator" content="DocBook XSL Stylesheets V1.79.1"/><meta name="description" content=""/><meta name="keywords" content="gluster, glusterfs, glusterfs-server, , , "/></head><body><section xml:lang="en-us" class="article" id="idp1"><div class="titlepage"><div><div><h2 class="title">Glusterfs</h2></div><div><h3 class="subtitle"><em>http://netkiller.github.io/journal/glusterfs.html</em></h3></div><div><div class="author"><h3 class="author"><span class="honorific">Mr</span>. <span class="firstname">Neo Chen</span> <span class="surname">(陈景峯)</span>, <span class="lineage">netkiller, BG7NYT</span></h3><div class="affiliation"><div class="address"><p><br/>
				<span class="country">中国</span><span class="state">广东省</span><span class="city">深圳市</span><span class="street">龙华新区民治街道溪山美地</span><br/>
				<span class="postcode">518131</span><br/>
				<span class="phone">+86 13113668890</span><br/>
				<br/>
				<code class="email">&lt;<a class="email" href="mailto:netkiller@msn.com">netkiller@msn.com</a>&gt;</code><br/>
			</p></div></div></div></div><div><div class="legalnotice" id="legalnotice"><p class="legalnotice-title"><strong>版权声明</strong></p><p>转载请与作者联系，转载时请务必标明文章原始出处和作者信息及本声明。</p><table style="border: 0; " class="simplelist"><tr><td>
		<a class="ulink" href="http://creativecommons.org/licenses/by/3.0/" target="_top">
			<div><table style="border: 0; width: 180px; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/by-nc-sa.png" width="180"/></td></tr></table></div>
		</a>
		</td><td>
			<table style="border: 0; " class="simplelist"><tr><td>
					文档出处:
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.github.io/" target="_top">http://netkiller.github.io</a>
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.sourceforge.net/" target="_top">http://netkiller.sourceforge.net</a>
				</td></tr></table>
		</td><td>
			<a class="ulink" href="/images/weixin.jpg" target="_top"><div><table style="border: 0; width: 80px; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/weixin.jpg" width="80"/></td></tr></table></div></a>
		</td><td>
			<p>微信扫描二维码进入 Netkiller 微信订阅号 </p>
			<p>QQ群：128659835 请注明“读者”</p>
		</td></tr></table><p/></div></div><div><p class="pubdate">2014-09-23</p></div><div><div class="abstract"><div class="abstract-title">Abstract</div>

		</div></div></div><hr/></div><div class="toc"><div class="toc-title">Table of Contents</div><ul class="toc"><li><span class="section"><a href="#idp2">1. Host</a></span></li><li><span class="section"><a href="#idp3">2. Storage bricks</a></span></li><li><span class="section"><a href="#idp4">3. Server</a></span></li><li><span class="section"><a href="#idp5">4. Check brick nodes</a></span></li><li><span class="section"><a href="#idp7">5. Client</a></span><ul><li><span class="section"><a href="#idp6">5.1. /etc/fstab</a></span></li></ul></li><li><span class="section"><a href="#idp8">6. Other</a></span></li></ul></div>
	
	<section class="section" id="idp2"><div class="titlepage"><div><div><h2 class="title" style="clear: both">1. Host</h2></div></div></div>
		
		<pre class="screen">
# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.6.12	client1.example.com client1
192.168.6.13	server.example.com server

192.168.6.1	brick1.example.com brick1
192.168.2.1	brick2.example.com brick2
		</pre>
	</section>	
	<section class="section" id="idp3"><div class="titlepage"><div><div><h2 class="title" style="clear: both">2. Storage bricks</h2></div></div></div>
		
		<p>brick1, brick2</p>
		<p>Install Gluster packages on both nodes</p>
		<pre class="screen">
wget http://download.gluster.org/pub/gluster/glusterfs/3.5/3.5.2/CentOS/glusterfs-epel.repo -P /etc/yum.repos.d/
yum install -y glusterfs-server
chkconfig glusterd on
service glusterd start
service iptables stop
		</pre>
		<p/>
		<pre class="screen">
mkdir /opt/export		
		</pre>
	</section>
	<section class="section" id="idp4"><div class="titlepage"><div><div><h2 class="title" style="clear: both">3. Server</h2></div></div></div>
		
		<p>Install Gluster packages on server nodes</p>
		<pre class="screen">
wget http://download.gluster.org/pub/gluster/glusterfs/3.5/3.5.2/CentOS/glusterfs-epel.repo -P /etc/yum.repos.d/
yum install -y glusterfs-server
chkconfig glusterd on
service glusterd start
		</pre>
		<p>Run the gluster peer probe command</p>
		<pre class="screen">
# gluster peer probe brick1.example.com
peer probe: success. 
# gluster peer probe brick2.example.com
peer probe: success. 
		</pre>
		<p/>
		<pre class="screen">
# gluster peer status
Number of Peers: 2

Hostname: brick1.example.com
Uuid: c8acab33-ed6a-4aa5-8b77-5be84695ffce
State: Peer in Cluster (Connected)

Hostname: brick2.example.com
Uuid: bf309355-7444-48e4-a7ea-25223c771160
State: Peer in Cluster (Connected)
		</pre>
		<p>Configure your Gluster volume</p>
		<pre class="screen">
# gluster volume create testvol replica 2 transport tcp brick1.example.com:/opt/export brick2.example.com:/opt/export
volume create: testvol: success: please start the volume to access data
		</pre>
		<p/>
		<pre class="screen">
# gluster volume start testvol
volume start: testvol: success		
		</pre>
		<p/>
		<pre class="screen">
# gluster volume info
 
Volume Name: testvol
Type: Replicate
Volume ID: cd4cdf2f-178b-4160-9ee9-c579266753de
Status: Started
Number of Bricks: 1 x 2 = 2
Transport-type: tcp
Bricks:
Brick1: brick1.example.com:/opt/export
Brick2: brick2.example.com:/opt/export		
		</pre>
		<p/>
		<pre class="screen">
# gluster volume set testvol auth.allow client.example.com
volume set: success
		</pre>
		<p/>
		<pre class="screen">
# gluster volume info
 
Volume Name: testvol
Type: Replicate
Volume ID: cd4cdf2f-178b-4160-9ee9-c579266753de
Status: Started
Number of Bricks: 1 x 2 = 2
Transport-type: tcp
Bricks:
Brick1: brick1.example.com:/opt/export
Brick2: brick2.example.com:/opt/export
Options Reconfigured:
auth.allow: client.example.com		
		</pre>
	</section>
	<section class="section" id="idp5"><div class="titlepage"><div><div><h2 class="title" style="clear: both">4. Check brick nodes</h2></div></div></div>
		
		<p>netstat -tap | grep glusterfsd</p>
		<pre class="screen">
# netstat -tap | grep glusterfsd
tcp        0      0 *:49152                     *:*                         LISTEN      13841/glusterfsd    
tcp        0      0 brick1.example.com:49152     brick1.example.com:1014      ESTABLISHED 13841/glusterfsd    
tcp        0      0 brick1.example.com:exp1      brick1.example.com:24007     ESTABLISHED 13841/glusterfsd    
tcp        0      0 brick1.example.com:49152     brick2.example.com:1011      ESTABLISHED 13841/glusterfsd    
tcp        0      0 brick1.example.com:49152     brick2.example.com:1012      ESTABLISHED 13841/glusterfsd    
tcp        0      0 brick1.example.com:49152     server.example.com:1017     ESTABLISHED 13841/glusterfsd    
tcp        0      0 brick1.example.com:49152     brick1.example.com:1020      ESTABLISHED 13841/glusterfsd   
		</pre>
	</section>
	<section class="section" id="idp7"><div class="titlepage"><div><div><h2 class="title" style="clear: both">5. Client</h2></div></div></div>
		
		<p>Install Gluster packages on client nodes</p>
		<pre class="screen">
wget http://download.gluster.org/pub/gluster/glusterfs/3.5/3.5.2/CentOS/glusterfs-epel.repo -P /etc/yum.repos.d/
yum install -y glusterfs-client
		</pre>
		<p>Test using the volume</p>
		<pre class="screen">
mkdir /mnt/glusterfs
mount.glusterfs server.example.com:/testvol /mnt/glusterfs		
		</pre>
		<p>Add an entry to /etc/fstab</p>
		<pre class="screen">
server1.example.com:/testvol /mnt/glusterfs glusterfs defaults,_netdev 0 0
		</pre>
		<p/>
		<pre class="screen">
# mount
/dev/vda1 on / type ext4 (rw)
proc on /proc type proc (rw)
sysfs on /sys type sysfs (rw)
devpts on /dev/pts type devpts (rw,gid=5,mode=620)
tmpfs on /dev/shm type tmpfs (rw)
none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
server.example.com:/testvol on /mnt/glusterfs type fuse.glusterfs (rw,default_permissions,allow_other,max_read=131072)		

# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/vda1              38G  2.3G   34G   7% /
tmpfs                 939M     0  939M   0% /dev/shm
server.example.com:/testvol
                      477G  359G  101G  79% /mnt/glusterfs
		</pre>
		<p/>
		<pre class="screen">
# touch /mnt/glusterfs/hello
# ll /mnt/glusterfs/
total 0
-rw-r--r-- 1 root root 0 Sep 23 14:31 hello
		</pre>
		<p>brick1</p>
		<pre class="screen">
# ll /opt/export/
total 0
-rw-r--r-- 2 root root 0 Sep 23 14:31 hello
		</pre>
		<p>brick2</p>
		<pre class="screen">
# ll /opt/export/
total 0
-rw-r--r-- 2 root root 0 Sep 23 14:31 hello
		</pre>	
		<section class="section" id="idp6"><div class="titlepage"><div><div><h3 class="title">5.1. /etc/fstab</h3></div></div></div>
			
			<p>Add an entry to /etc/fstab</p>
			<pre class="screen">
server1.example.com:/testvol /mnt/glusterfs glusterfs defaults,_netdev 0 0
			</pre>
		</section>				
	</section>
	<section class="section" id="idp8"><div class="titlepage"><div><div><h2 class="title" style="clear: both">6. Other</h2></div></div></div>
		
		<p>stop volume</p>
		<pre class="screen">
# gluster volume stop testvol
Stopping volume will make its data inaccessible. Do you want to continue? (y/n) y
volume stop: testvol: success
		</pre>
		<p>delete volume</p>
		<pre class="screen">
# gluster volume delete testvol
Deleting volume will erase all information about the volume. Do you want to continue? (y/n) y
volume delete: testvol: success		
		</pre>
		<pre class="screen">
# gluster peer datach brick1.example.com
		</pre>
		<pre class="screen">
# gluster volume remove-brick testvol brick1.example.com:/export/u01		
		</pre>
	</section>	
</section><div xmlns="" id="disqus_thread"/><script xmlns="">

var disqus_config = function () {
this.page.url = "http://www.netkiller.cn";  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'netkiller'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//netkiller.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script><noscript xmlns="">Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><br xmlns=""/><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"/></body></html>