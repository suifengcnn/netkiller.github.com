<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>日志归档与数据挖掘</title><link rel="stylesheet" type="text/css" href="docbook.css"/><link rel="stylesheet" type="text/css" href="/journal/journal.css"/><meta name="generator" content="DocBook XSL Stylesheets V1.79.1"/><meta name="description" content="2013-03-19 第一版 2014-12-16 第二版"/><meta name="keywords" content="iptables, access.log, error.log"/></head><body><section xml:lang="zh-cn" class="article" id="idp1"><div class="titlepage"><div><div><h2 class="title">日志归档与数据挖掘</h2></div><div><h3 class="subtitle"><em>http://netkiller.github.io/journal/log.html</em></h3></div><div><div class="author"><h3 class="author"><span class="honorific">Mr</span>. <span class="firstname">Neo Chen</span> <span class="surname">(陈景峯)</span>, <span class="lineage">netkiller, BG7NYT</span></h3><div class="affiliation">
			<div class="address"><p><br/>
				<span class="country">中国</span><span class="state">广东省</span><span class="city">深圳市</span><span class="street">龙华新区民治街道溪山美地</span><br/>
				<span class="postcode">518131</span><br/>
				<span class="phone">+86 13113668890</span><br/>
				<br/>
				<code class="email">&lt;<a class="email" href="mailto:netkiller@msn.com">netkiller@msn.com</a>&gt;</code><br/>
			</p></div>
		</div></div></div><div><p class="copyright">版权 © 2013, 2014 Netkiller. All rights reserved.</p></div><div><div class="legalnotice" id="legalnotice">
	<p class="legalnotice-title"><strong>版权声明</strong></p>
	<p>转载请与作者联系，转载时请务必标明文章原始出处和作者信息及本声明。</p>
	<table style="border: 0; " class="simplelist"><tr><td>
		<a class="ulink" href="http://creativecommons.org/licenses/by/3.0/" target="_top">
			<div><table style="border: 0; width: 180px; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/by-nc-sa.png" width="180"/></td></tr></table></div>
		</a>
		</td><td>
			<table style="border: 0; " class="simplelist"><tr><td>
					文档出处:
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.github.io/" target="_top">http://netkiller.github.io</a>
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.sourceforge.net/" target="_top">http://netkiller.sourceforge.net</a>
				</td></tr></table>
		</td><td>
			<a class="ulink" href="/images/weixin.jpg" target="_top"><div><table style="border: 0; width: 80px; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/weixin.jpg" width="80"/></td></tr></table></div></a>
		</td><td>
			<p>微信扫描二维码进入 Netkiller 微信订阅号 </p>
			<p>QQ群：128659835 请注明“读者”</p>
		</td></tr></table>
	<p/>
</div></div><div><p class="pubdate">2017-06-16</p></div><div><div class="abstract"><div class="abstract-title">摘要</div>
			<p>2013-03-19 第一版</p>
			<p>2014-12-16 第二版</p>
		</div></div></div><hr/></div><div class="toc"><div class="toc-title">目录</div><ul class="toc"><li><span class="section"><a href="#what">1. 什么日志归档</a></span></li><li><span class="section"><a href="#why">2. 为什么要做日志归档</a></span></li><li><span class="section"><a href="#when">3. 何时做日志归档</a></span></li><li><span class="section"><a href="#where">4. 归档日志放在哪里</a></span></li><li><span class="section"><a href="#who">5. 谁去做日志归档</a></span></li><li><span class="section"><a href="#how">6. 怎样做日志归档</a></span><ul><li><span class="section"><a href="#idp7">6.1. 日志格式转换</a></span><ul><li><span class="section"><a href="#idp3">6.1.1. 将日志放入数据库</a></span></li><li><span class="section"><a href="#idp4">6.1.2. Apache Pipe</a></span></li><li><span class="section"><a href="#idp5">6.1.3. Log format</a></span></li><li><span class="section"><a href="#idp6">6.1.4. 日志导入到 MongoDB</a></span></li></ul></li><li><span class="section"><a href="#idp12">6.2. 日志中心方案</a></span><ul><li><span class="section"><a href="#idp8">6.2.1. 软件安装</a></span></li><li><span class="section"><a href="#idp9">6.2.2. 节点推送端</a></span></li><li><span class="section"><a href="#idp10">6.2.3. 日志收集端</a></span></li><li><span class="section"><a href="#idp11">6.2.4. 日志监控</a></span></li></ul></li></ul></li></ul></div>
	

	<section class="section" id="what"><div class="titlepage"><div><div><h2 class="title" style="clear: both">1. 什么日志归档</h2></div></div></div>
		
		<p>归档，是指将日志整理完毕且有保存价值的文件，经系统整理交日志服务器保存的过程。</p>
	</section>
	<section class="section" id="why"><div class="titlepage"><div><div><h2 class="title" style="clear: both">2. 为什么要做日志归档</h2></div></div></div>
		
		<div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">随时调出历史日志查询。</li><li class="listitem">通过日志做数据挖掘，挖掘有价值的数据。</li><li class="listitem">查看应用程序的工作状态</li></ul></div>
	</section>
	<section class="section" id="when"><div class="titlepage"><div><div><h2 class="title" style="clear: both">3. 何时做日志归档</h2></div></div></div>
		
		<p>日志归档应该是企业规定的一项制度(“归档制度”)，系统建设之初就应该考虑到日志归档问题。如果你的企业没有这项工作或制度，在看完本文后建议你立即实施。</p>
	</section>
	<section class="section" id="where"><div class="titlepage"><div><div><h2 class="title" style="clear: both">4. 归档日志放在哪里</h2></div></div></div>
		
		<p>简单的可以采用单节点服务器加备份方案。</p>
		<p>随着日志规模扩大，未来必须采用分布式文件系统，甚至涉及到远程异地容灾。</p>
	</section>
	<section class="section" id="who"><div class="titlepage"><div><div><h2 class="title" style="clear: both">5. 谁去做日志归档</h2></div></div></div>
		
		<p>我的答案是日志归档自动化，人工检查或抽检。</p>
	</section>
	<section class="section" id="how"><div class="titlepage"><div><div><h2 class="title" style="clear: both">6. 怎样做日志归档</h2></div></div></div>
		
		<p>将所有服务器的日志都汇总到一处，有几种方法</p>
		<div class="itemizedlist"><div class="itemizedlist-title">日志归档常用方法：</div><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">ftp 定是下载， 这种做法适合小文件且日志量不大，定是下载到指定服务器，缺点是重复传输，实时性差。</li><li class="listitem">rsyslog 一类的程序，比较通用，但扩展不便。</li><li class="listitem">rsync 定是同步，适合打文件同步，好于FTP，实时性差。</li></ul></div>
		<section class="section" id="idp7"><div class="titlepage"><div><div><h3 class="title">6.1. 日志格式转换</h3></div></div></div>
			
			<p>首先我来介绍一种简单的方案</p>
			<p>我用D语言写了一个程序将 WEB 日志正则分解然后通过管道传递给数据库处理程序 </p>
			<section class="section" id="idp3"><div class="titlepage"><div><div><h4 class="title">6.1.1. 将日志放入数据库</h4></div></div></div>
				
				<p>将WEB服务器日志通过管道处理然后写入数据库</p>
				<p>处理程序源码</p>
				<pre class="screen">
				
$ vim match.d
import std.regex;
import std.stdio;
import std.string;
import std.array;

void main()
{
    // nginx
	//auto r = regex(`^(\S+) (\S+) (\S+) \[(.+)\] "([^"]+)" ([0-9]{3}) ([0-9]+) "([^"]+)" "([^"]+)" "([^"]+)"`);

	// apache2
	auto r = regex(`^(\S+) (\S+) (\S+) \[(.+)\] "([^"]+)" ([0-9]{3}) ([0-9]+) "([^"]+)" "([^"]+)"`);

	foreach(line; stdin.byLine)
	{

		foreach(m; match(line, r)){
			//writeln(m.hit);
			auto c = m.captures;
			c.popFront();
			//writeln(c);
			auto value = join(c, "\",\"");
			auto sql = format("insert into log(remote_addr,unknow,remote_user,time_local,request,status,body_bytes_sent,http_referer,http_user_agent,http_x_forwarded_for) value(\"%s\");", value );
			writeln(sql);
		}
	}
}
				
				</pre>
				<p>编译</p>
				<pre class="screen">
$ dmd match.d
$ strip match

$ ls
match  match.d  match.o
				</pre>
				<p>简单用法</p>
				<pre class="screen">
$ cat access.log | ./match
				</pre>
				<p>高级用法</p>
				<pre class="screen">
				
$ cat access.log | match | mysql -hlocalhost -ulog -p123456 logging
				
				</pre>
				<p>实时处理日志，首先创建一个管道，寻该日志文件写入管道中。</p>
				<pre class="screen">
cat  管道名 | match | mysql -hlocalhost -ulog -p123456 logging
				</pre>
				<p>这样就可以实现实时日志插入。</p>
				<div class="tip"><h3 class="title">提示</h3>
					<p>上面程序稍加修改即可实现Hbase, Hypertable 本版</p>
				</div>
			</section>
			<section class="section" id="idp4"><div class="titlepage"><div><div><h4 class="title">6.1.2. Apache Pipe</h4></div></div></div>
				
				<p>Apache 日志管道过滤 CustomLog "| /srv/match &gt;&gt; /tmp/access.log" combined</p>
				<pre class="screen">
				
&lt;VirtualHost *:80&gt;
        ServerAdmin webmaster@localhost

        #DocumentRoot /var/www
        DocumentRoot /www
        &lt;Directory /&gt;
                Options FollowSymLinks
                AllowOverride None
        &lt;/Directory&gt;
        #&lt;Directory /var/www/&gt;
        &lt;Directory /www/&gt;
                Options Indexes FollowSymLinks MultiViews
                AllowOverride None
                Order allow,deny
                allow from all
        &lt;/Directory&gt;

        ScriptAlias /cgi-bin/ /usr/lib/cgi-bin/
        &lt;Directory "/usr/lib/cgi-bin"&gt;
                AllowOverride None
                Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch
                Order allow,deny
                Allow from all
        &lt;/Directory&gt;

        ErrorLog ${APACHE_LOG_DIR}/error.log

        # Possible values include: debug, info, notice, warn, error, crit,
        # alert, emerg.
        LogLevel warn

        #CustomLog ${APACHE_LOG_DIR}/access.log combined
        CustomLog "| /srv/match &gt;&gt; /tmp/access.log" combined

    Alias /doc/ "/usr/share/doc/"
    &lt;Directory "/usr/share/doc/"&gt;
        Options Indexes MultiViews FollowSymLinks
        AllowOverride None
        Order deny,allow
        Deny from all
        Allow from 127.0.0.0/255.0.0.0 ::1/128
    &lt;/Directory&gt;

&lt;/VirtualHost&gt;
				
				</pre>
				<p>经过管道转换过的日志效果</p>
				<pre class="screen">
				
$ tail /tmp/access.log
insert into log(remote_addr,unknow,remote_user,time_local,request,status,body_bytes_sent,http_referer,http_user_agent,http_x_forwarded_for) value("192.168.6.30","-","-","21/Mar/2013:16:11:00 +0800","GET / HTTP/1.1","304","208","-","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.172 Safari/537.22");
insert into log(remote_addr,unknow,remote_user,time_local,request,status,body_bytes_sent,http_referer,http_user_agent,http_x_forwarded_for) value("192.168.6.30","-","-","21/Mar/2013:16:11:00 +0800","GET /favicon.ico HTTP/1.1","404","501","-","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.172 Safari/537.22");
insert into log(remote_addr,unknow,remote_user,time_local,request,status,body_bytes_sent,http_referer,http_user_agent,http_x_forwarded_for) value("192.168.6.30","-","-","21/Mar/2013:16:11:00 +0800","GET / HTTP/1.1","304","208","-","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.172 Safari/537.22");
				
				</pre>
			</section>
			<section class="section" id="idp5"><div class="titlepage"><div><div><h4 class="title">6.1.3. Log format</h4></div></div></div>
				
				<p>通过定义LogFormat可以直接输出SQL形式的日志</p>
				<p>Apache</p>
				<pre class="screen">
LogFormat "%v:%p %h %l %u %t \"%r\" %&gt;s %O \"%{Referer}i\" \"%{User-Agent}i\"" vhost_combined
LogFormat "%h %l %u %t \"%r\" %&gt;s %O \"%{Referer}i\" \"%{User-Agent}i\"" combined
LogFormat "%h %l %u %t \"%r\" %&gt;s %O" common
LogFormat "%{Referer}i -&gt; %U" referer
LogFormat "%{User-agent}i" agent
				</pre>
				<p>Nginx</p>
				<pre class="screen">
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
				</pre>
				<p>但对于系统管理员使用grep,awk,sed,sort,uniq分析时造成一定的麻烦。所以我建议仍然采用正则分解</p>
				<p>产生有规则日志格式，Apache：</p>
				<pre class="screen">
LogFormat \
        "\"%h\",%{%Y%m%d%H%M%S}t,%&gt;s,\"%b\",\"%{Content-Type}o\",  \
        \"%U\",\"%{Referer}i\",\"%{User-Agent}i\""
				</pre>
				<p>将access.log文件导入到mysql中</p>
				<pre class="screen">
LOAD DATA INFILE '/local/access_log' INTO TABLE tbl_name
FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"' ESCAPED BY '\\'
				</pre>
			</section>

			<section class="section" id="idp6"><div class="titlepage"><div><div><h4 class="title">6.1.4. 日志导入到 MongoDB</h4></div></div></div>
				
				<pre class="screen">
# rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
# yum install mongodb
				</pre>
				<p>D语言日志处理程序</p>
				<pre class="screen">
				
import std.regex;
//import std.range;
import std.stdio;
import std.string;
import std.array;

void main()
{
	// nginx
	auto r = regex(`^(\S+) (\S+) (\S+) \[(.+)\] "([^"]+)" ([0-9]{3}) ([0-9]+) "([^"]+)" "([^"]+)" "([^"]+)"`);
	// apache2
	//auto r = regex(`^(\S+) (\S+) (\S+) \[(.+)\] "([^"]+)" ([0-9]{3}) ([0-9]+) "([^"]+)" "([^"]+)"`);
	foreach(line; stdin.byLine)
	{
		//writeln(line);
		//auto m = match(line, r);
		foreach(m; match(line, r)){
			//writeln(m.hit);
			auto c = m.captures;
			c.popFront();
			//writeln(c);
			/*
			SQL
			auto value = join(c, "\",\"");
			auto sql = format("insert into log(remote_addr,unknow,remote_user,time_local,request,status,body_bytes_sent,http_referer,http_user_agent,http_x_forwarded_for) value(\"%s\");", value );
			writeln(sql);
			*/
			// MongoDB
			string bson = format("db.logging.access.save({
						'remote_addr': '%s',
						'remote_user': '%s',
						'time_local': '%s',
						'request': '%s',
						'status': '%s',
						'body_bytes_sent':'%s',
						'http_referer': '%s',
						'http_user_agent': '%s',
						'http_x_forwarded_for': '%s'
						})",
						c[0],c[2],c[3],c[4],c[5],c[6],c[7],c[8],c[9]
						);
			writeln(bson);

		}
	}

}
				
				</pre>
				<p>编译日志处理程序</p>
				<pre class="screen">
dmd mlog.d
				</pre>
				<p>用法</p>
				<pre class="screen">
cat /var/log/nginx/access.log | mlog | mongo 192.169.0.5/logging -uxxx -pxxx
				</pre>
				<p>处理压错过的日志</p>
				<pre class="screen">
# zcat /var/log/nginx/*.access.log-*.gz | /srv/mlog | mongo 192.168.6.1/logging -uneo -pchen
				</pre>
				<p>实时采集日志</p>
				<pre class="screen">
tail -f /var/log/nginx/access.log | mlog | mongo 192.169.0.5/logging -uxxx -pxxx
				</pre>
			</section>

		</section>

		<section class="section" id="idp12"><div class="titlepage"><div><div><h3 class="title">6.2. 日志中心方案</h3></div></div></div>
			
			<p>上面的方案虽然简单，但太依赖系统管理员，需要配置很多服务器，每种应用软件产生的日志都不同，所以很复杂。如果中途出现故障，将会丢失一部日志。</p>
			<p>于是我又回到了起点，所有日志存放在自己的服务器上，定时将他们同步到日志服务器，这样解决了日志归档。远程收集日志，通过UDP协议推送汇总到日志中心，这样解决了日志实时监控、抓取等等对实时性要求较高的需求。</p>
			<p>为此我用了两三天写了一个软件，下载地址：https://github.com/netkiller/logging</p>
			<p>这种方案并不是最佳的，只是比较适合我的场景，而且我仅用了两三天就完成了软件的开发。后面我会进一步扩展，增加消息队列传送日志的功能。</p>
			<section class="section" id="idp8"><div class="titlepage"><div><div><h4 class="title">6.2.1. 软件安装</h4></div></div></div>
				
				<pre class="screen">
$ git clone https://github.com/netkiller/logging.git
$ cd logging
$ python3 setup.py sdist
$ python3 setup.py install
				</pre>
			</section>
			<section class="section" id="idp9"><div class="titlepage"><div><div><h4 class="title">6.2.2. 节点推送端</h4></div></div></div>
				
				<p>安装启动脚本</p>
				<p>CentOS</p>
				<pre class="screen">
# cp logging/init.d/ulog /etc/init.d			
				</pre>
				<p>Ubuntu</p>
				<pre class="screen">
$ sudo cp init.d/ulog /etc/init.d/	

$ service ulog 
Usage: /etc/init.d/ulog {start|stop|status|restart}			
				</pre>
				<p>配置脚本，打开 /etc/init.d/ulog 文件</p>
				<p>配置日志中心的IP地址</p>
				<pre class="screen">
HOST=xxx.xxx.xxx.xxx
				</pre>
				<p>然后配置端口与采集那些日志</p>
				<pre class="screen">
				
	done &lt;&lt; EOF
1213 /var/log/nginx/access.log
1214 /tmp/test.log
1215 /tmp/$(date +"%Y-%m-%d.%H:%M:%S").log
EOF
				
				</pre>
				<p>格式为</p>
				<pre class="screen">
Port | Logfile
------------------------------
1213 /var/log/nginx/access.log
1214 /tmp/test.log
1215 /tmp/$(date +"%Y-%m-%d.%H:%M:%S").log
				</pre>
				<p>1213 目的端口号（日志中心端口）后面是你需要监控的日志，如果日志每日产生一个文件写法类似 /tmp/$(date +"%Y-%m-%d.%H:%M:%S").log</p>
				<div class="tip"><h3 class="title">提示</h3>每日产生一个新日志文件需要定时重启 ulog 方法是 /etc/init.d/ulog restart</div>
				<p>配置完成后启动推送程序</p>
				<pre class="screen">
# service ulog start
				</pre>
				<p>查看状态</p>
				<pre class="screen">
$ service ulog status
13865 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/rlog -d -H 127.0.0.1 -p 1213 /var/log/nginx/access.log				
				</pre>
				<p>停止推送</p>
				<pre class="screen">
# service ulog stop				
				</pre>
			</section>
			<section class="section" id="idp10"><div class="titlepage"><div><div><h4 class="title">6.2.3. 日志收集端</h4></div></div></div>
				
				<pre class="screen">
# cp logging/init.d/ucollection /etc/init.d

# /etc/init.d/ucollection 
Usage: /etc/init.d/ucollection {start|stop|status|restart}
				</pre>
				<p>配置接收端口与保存文件，打开 /etc/init.d/ucollection 文件，看到下面段落</p>
				<pre class="screen">
				
done &lt;&lt; EOF
1213 /tmp/nginx/access.log
1214 /tmp/test/test.log
1215 /tmp/app/$(date +"%Y-%m-%d.%H:%M:%S").log
1216 /tmp/db/$(date +"%Y-%m-%d")/mysql.log
1217 /tmp/cache/$(date +"%Y")/$(date +"%m")/$(date +"%d")/cache.log
EOF
				
				</pre>
				<p>格式如下，表示接收来自1213端口的数据，并保存到/tmp/nginx/access.log文件中。</p>
				<pre class="screen">
Port | Logfile
1213 /tmp/nginx/access.log
				</pre>
				<p>如果需要分割日志配置如下</p>
				<pre class="screen">
1217 /tmp/cache/$(date +"%Y")/$(date +"%m")/$(date +"%d")/cache.log
				</pre>
				<p>上面配置日志文件将会产生在下面的目录中</p>
				<pre class="screen">
$ find /tmp/cache/
/tmp/cache/
/tmp/cache/2014
/tmp/cache/2014/12
/tmp/cache/2014/12/16
/tmp/cache/2014/12/16/cache.log
				</pre>
				<div class="tip"><h3 class="title">提示</h3>同样，如果分割日志需要重启收集端程序。</div>
				<p>启动收集端</p>
				<pre class="screen">
# service ulog start	
				</pre>
				<p>停止程序</p>
				<pre class="screen">
# service ulog stop			
				</pre>
				<p>查看状态</p>
				<pre class="screen">
$ init.d/ucollection status
12429 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/collection -d -p 1213 -l /tmp/nginx/access.log
12432 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/collection -d -p 1214 -l /tmp/test/test.log
12435 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/collection -d -p 1215 -l /tmp/app/2014-12-16.09:55:15.log
12438 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/collection -d -p 1216 -l /tmp/db/2014-12-16/mysql.log
12441 pts/16   S      0:00 /usr/bin/python3 /usr/local/bin/collection -d -p 1217 -l /tmp/cache/2014/12/16/cache.log
				</pre>
			</section>
			<section class="section" id="idp11"><div class="titlepage"><div><div><h4 class="title">6.2.4. 日志监控</h4></div></div></div>
				
				<p>监控来自1217宽口的数据</p>
				<pre class="screen">
$ collection -p 1213

192.168.6.20 - - [16/Dec/2014:15:06:23 +0800] "GET /journal/log.html HTTP/1.1" 304 0 "-" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
192.168.6.20 - - [16/Dec/2014:15:06:23 +0800] "GET /journal/docbook.css HTTP/1.1" 304 0 "http://192.168.6.2/journal/log.html" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
192.168.6.20 - - [16/Dec/2014:15:06:23 +0800] "GET /journal/journal.css HTTP/1.1" 304 0 "http://192.168.6.2/journal/log.html" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
192.168.6.20 - - [16/Dec/2014:15:06:23 +0800] "GET /images/by-nc-sa.png HTTP/1.1" 304 0 "http://192.168.6.2/journal/log.html" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
192.168.6.20 - - [16/Dec/2014:15:06:23 +0800] "GET /js/q.js HTTP/1.1" 304 0 "http://192.168.6.2/journal/log.html" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
				</pre>
				<p>启动后实时将最新日志传送过来</p>
			</section>
		</section>
	</section>

</section><div xmlns="" id="disqus_thread"/><script xmlns="">

var disqus_config = function () {
this.page.url = "http://www.netkiller.cn";  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'netkiller'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//netkiller.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script><noscript xmlns="">Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><br xmlns=""/><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"/></body></html>