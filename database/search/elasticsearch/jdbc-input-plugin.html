<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>8.11. Migrating MySQL Data into Elasticsearch using logstash</title><link rel="stylesheet" type="text/css" href="../..//docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets V1.79.1" /><meta name="keywords" content="MySQL, PostgreSQL, Oracle, NoSQL, ER, TokyoCabinet/Tyrant, Memcache, Membase, Redis, Flare, Voldemort, LevelDB, MongoDB, GreenSQL, RDBMS, ORDBMS" /><link rel="home" href="../../index.html" title="Netkiller Database 手札" /><link rel="up" href="index.html" title="第 8 章 Elasticsearch" /><link rel="prev" href="example.html" title="8.10. Example" /><link rel="next" href="install.html" title="8.12. 安装 Elasticsearch 2.3" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> |
		<a xmlns="" href="//netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="/journal/index.html">杂文</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> |
	    <a xmlns="" href="https://github.com/netkiller">Github</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://cloud.tencent.com/developer/column/2078">云社区</a> |
	    <a xmlns="" href="https://yq.aliyun.com/u/netkiller/">云栖社区</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/video.html">视频教程</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">8.11. Migrating MySQL Data into Elasticsearch using logstash</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="example.html">上一页</a> </td><th width="60%" align="center">第 8 章 Elasticsearch</th><td width="20%" align="right"> <a accesskey="n" href="install.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="jdbc-input-plugin"></a>8.11. Migrating MySQL Data into Elasticsearch using logstash</h2></div></div></div>
		
		<p>https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html</p>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.install"></a>8.11.1. 安装 logstash</h3></div></div></div>
			
			<p>安装 JDBC 驱动 和 Logstash </p>
			<pre class="screen">
curl -s https://raw.githubusercontent.com/oscm/shell/master/database/mysql/5.7/mysql-connector-java.sh	 | bash			
curl -s https://raw.githubusercontent.com/oscm/shell/master/search/logstash/logstash-5.x.sh | bash
			</pre>
			<p>mysql 驱动文件位置在 /usr/share/java/mysql-connector-java.jar </p>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.config"></a>8.11.2. 配置 logstash</h3></div></div></div>
			
			<p>创建配置文件 /etc/logstash/conf.d/jdbc-mysql.conf</p>
			<pre class="screen">
			
mysql&gt; desc article;
+-------------+--------------+------+-----+---------+-------+
| Field       | Type         | Null | Key | Default | Extra |
+-------------+--------------+------+-----+---------+-------+
| id          | int(11)      | NO   |     | 0       |       |
| title       | mediumtext   | NO   |     | NULL    |       |
| description | mediumtext   | YES  |     | NULL    |       |
| author      | varchar(100) | YES  |     | NULL    |       |
| source      | varchar(100) | YES  |     | NULL    |       |
| ctime       | datetime     | NO   |     | NULL    |       |
| content     | longtext     | YES  |     | NULL    |       |
+-------------+--------------+------+-----+---------+-------+
7 rows in set (0.00 sec)
			
			</pre>
			<pre class="screen">
			
input {
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"
    statement =&gt; "select * from article"
  }
}
output {
    elasticsearch {
    		hosts =&gt; "localhost:9200"
        index =&gt; "information"
        document_type =&gt; "article"
        document_id =&gt; "%{id}"
        
    }
}
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.start"></a>8.11.3. 启动 Logstash</h3></div></div></div>
			
			<pre class="screen">
			
root@netkiller /var/log/logstash % systemctl restart logstash

root@netkiller /var/log/logstash % systemctl status logstash
● logstash.service - logstash
   Loaded: loaded (/etc/systemd/system/logstash.service; enabled; vendor preset: disabled)
   Active: active (running) since Mon 2017-07-31 09:35:00 CST; 11s ago
 Main PID: 10434 (java)
   CGroup: /system.slice/logstash.service
           └─10434 /usr/bin/java -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+DisableExplicitGC -Djava.awt.headless=true -Dfi...

Jul 31 09:35:00 netkiller systemd[1]: Started logstash.
Jul 31 09:35:00 netkiller systemd[1]: Starting logstash...
			
root@netkiller /var/log/logstash % cat logstash-plain.log 
[2017-07-31T09:35:28,169][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[http://localhost:9200/]}}
[2017-07-31T09:35:28,172][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://localhost:9200/, :path=&gt;"/"}
[2017-07-31T09:35:28,298][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=&gt;#&lt;Java::JavaNet::URI:0x453a18e9&gt;}
[2017-07-31T09:35:28,299][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=&gt;nil}
[2017-07-31T09:35:28,337][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=&gt;{"template"=&gt;"logstash-*", "version"=&gt;50001, "settings"=&gt;{"index.refresh_interval"=&gt;"5s"}, "mappings"=&gt;{"_default_"=&gt;{"_all"=&gt;{"enabled"=&gt;true, "norms"=&gt;false}, "dynamic_templates"=&gt;[{"message_field"=&gt;{"path_match"=&gt;"message", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false}}}, {"string_fields"=&gt;{"match"=&gt;"*", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false, "fields"=&gt;{"keyword"=&gt;{"type"=&gt;"keyword", "ignore_above"=&gt;256}}}}}], "properties"=&gt;{"@timestamp"=&gt;{"type"=&gt;"date", "include_in_all"=&gt;false}, "@version"=&gt;{"type"=&gt;"keyword", "include_in_all"=&gt;false}, "geoip"=&gt;{"dynamic"=&gt;true, "properties"=&gt;{"ip"=&gt;{"type"=&gt;"ip"}, "location"=&gt;{"type"=&gt;"geo_point"}, "latitude"=&gt;{"type"=&gt;"half_float"}, "longitude"=&gt;{"type"=&gt;"half_float"}}}}}}}}
[2017-07-31T09:35:28,344][INFO ][logstash.outputs.elasticsearch] Installing elasticsearch template to _template/logstash
[2017-07-31T09:35:28,465][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=&gt;"LogStash::Outputs::ElasticSearch", :hosts=&gt;[#&lt;Java::JavaNet::URI:0x66df34ae&gt;]}
[2017-07-31T09:35:28,483][INFO ][logstash.pipeline        ] Starting pipeline {"id"=&gt;"main", "pipeline.workers"=&gt;8, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;5, "pipeline.max_inflight"=&gt;1000}
[2017-07-31T09:35:29,562][INFO ][logstash.pipeline        ] Pipeline main started
[2017-07-31T09:35:29,700][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}
[2017-07-31T09:36:01,019][INFO ][logstash.inputs.jdbc     ] (0.006000s) select * from article	
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.test"></a>8.11.4. 验证</h3></div></div></div>
			
			<pre class="screen">
			
% curl -XGET 'http://localhost:9200/_all/_search?pretty'
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.template"></a>8.11.5. 配置模板</h3></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp29"></a>8.11.5.1. 全量导入</h4></div></div></div>
				
				<p>适合数据没有改变的归档数据或者只能增加没有修改的数据</p>
				<pre class="screen">
				
input {
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"
    statement =&gt; "select * from article"
  }
}
output {
    elasticsearch {
    		hosts =&gt; "localhost:9200"
        index =&gt; "information"
        document_type =&gt; "article"
        document_id =&gt; "%{id}"
        
    }
}
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp30"></a>8.11.5.2. 多表导入</h4></div></div></div>
				
				<p>多张数据表导入到 Elasticsearch</p>
				<pre class="screen">
				
# multiple inputs on logstash jdbc

input {
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"
    statement =&gt; "select * from article"
    type =&gt; "article"
  }
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"
    statement =&gt; "select * from comment"
    type =&gt; "comment"
  } 
}
output {
    elasticsearch {
    		hosts =&gt; "localhost:9200"
        index =&gt; "information"
        document_type =&gt; "%{type}"
        document_id =&gt; "%{id}"
        
    }
}				
				
				</pre>
				<p>需要在每一个jdbc配置项中加入 type 配置，然后 elasticsearch 配置项中加入 document_type =&gt; "%{type}" </p>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp31"></a>8.11.5.3. 通过 ID 主键字段增量复制数据</h4></div></div></div>
				
				<pre class="screen">
				
input {
  jdbc {
    statement =&gt; "SELECT id, mycolumn1, mycolumn2 FROM my_table WHERE id &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "id"
    tracking_column_type =&gt; "numeric"
    # ... other configuration bits
  }
}
				
				</pre>
				<p>tracking_column_type =&gt; "numeric" 可以声明 id 字段的数据类型, 如果不指定将会默认为日期</p>
				<pre class="screen">
[2017-07-31T11:08:00,193][INFO ][logstash.inputs.jdbc     ] (0.020000s) select * from article where id &gt; '2017-07-31 02:47:00'
				</pre>
				<p>如果复制不对称可以加入 clean_run =&gt; true 配置项，清楚数据</p>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp32"></a>8.11.5.4. 通过日期字段增量复制数据</h4></div></div></div>
				
				<pre class="screen">
				
input {
  jdbc {
    statement =&gt; "SELECT * FROM my_table WHERE create_date &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "create_date"
    # ... other configuration bits
  }
}
				
				</pre>
				<p>如果复制不对称可以加入 clean_run =&gt; true 配置项，清楚数据</p>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp33"></a>8.11.5.5. 指定SQL文件</h4></div></div></div>
				
				<p>statement_filepath 指定 SQL 文件，有时SQL太复杂写入 statement 配置项维护部方便，可以将 SQL 写入一个文本文件，然后使用 statement_filepath 配置项引用该文件。</p>
				<pre class="screen">
				
input {
    jdbc {
        jdbc_driver_library =&gt; "/path/to/driver.jar"
        jdbc_driver_class =&gt; "org.postgresql.Driver"
        jdbc_url =&gt; "jdbc://postgresql"
        jdbc_user =&gt; "neo"
        jdbc_password =&gt; "password"
        statement_filepath =&gt; "query.sql"
    }
}				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp34"></a>8.11.5.6. 参数传递</h4></div></div></div>
				
				<p>将需要复制的条件参数写入 parameters 配置项</p>
				<pre class="screen">
				
input {
  jdbc {
    jdbc_driver_library =&gt; "mysql-connector-java-5.1.36-bin.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/mydb"
    jdbc_user =&gt; "mysql"
    parameters =&gt; { "favorite_artist" =&gt; "Beethoven" }
    schedule =&gt; "* * * * *"
    statement =&gt; "SELECT * from songs where artist = :favorite_artist"
  }
}				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp35"></a>8.11.5.7. 控制返回JDBC数据量</h4></div></div></div>
				
				<pre class="screen">
	jdbc_fetch_size =&gt; 1000  #jdbc获取数据的数量大小
	jdbc_page_size =&gt; 1000 #jdbc一页的大小，
	jdbc_paging_enabled =&gt; true  #和jdbc_page_size组合，将statement的查询分解成多个查询,相当于: SELECT * FROM table LIMIT 1000 OFFSET 4000 				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp36"></a>8.11.5.8. 输出到不同的 Elasticsearch 中</h4></div></div></div>
				
				<p>通过 if [type]=="news" 执行不同的区块，实现将不同的type输出到指定的 index 中。</p>
				<pre class="screen">
output {
	if [type]=="news" {
	  elasticsearch {
	  	hosts =&gt; "node1.netkiller.cn:9200"
		index =&gt; "information"
		document_id =&gt; "%{id}"
	  }
	}
	
	if [type]=="comment" {
	  elasticsearch {
		hosts =&gt; "node2.netkiller.cn:9200"
		index =&gt; "information"
		document_id =&gt; "%{id}"
	  }
	}
}		
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idp37"></a>8.11.5.9. 日期格式转换</h4></div></div></div>
				
				<p>日期格式化, 将ISO 8601日期格式转换为 %Y-%m-%d %H:%M:%S</p>
				<pre class="screen">
				
input {
	jdbc {
		jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
		jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
		jdbc_connection_string =&gt; "jdbc:mysql://127.0.0.1:3306/cms"
		jdbc_user =&gt; "cms"
		jdbc_password =&gt; "123456"
		schedule =&gt; "* * * * *"
		statement =&gt; "select * from article limit 5"
	}

}
filter {
	ruby {
		init =&gt; "require 'time'"
        code =&gt; "event.set('ctime', event.get('ctime').time.localtime.strftime('%Y-%m-%d %H:%M:%S'))"
    }

	ruby {
		init =&gt; "require 'time'"
        code =&gt; "event.set('mtime', event.get('mtime').time.localtime.strftime('%Y-%m-%d %H:%M:%S'))"
    }
}
output {

	stdout {
		codec =&gt; rubydebug
	}

}				
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="logstash.example"></a>8.11.5.10. example</h4></div></div></div>
				
				<p>下面的例子实现了新数据复制，旧数据更新</p>
				<pre class="screen">
				
input {
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"	#定时cron的表达式,这里是每分钟执行一次
    statement =&gt; "select id, title, description, author, source, ctime, content from article where id &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "id"
    tracking_column_type =&gt; "numeric" 
    record_last_run =&gt; true
    last_run_metadata_path =&gt; "/var/tmp/article.last"
  }
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"	#定时cron的表达式,这里是每分钟执行一次
    statement =&gt; "select * from article where ctime &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "ctime"
    tracking_column_type =&gt; "timestamp" 
    record_last_run =&gt; true
    last_run_metadata_path =&gt; "/var/tmp/article-ctime.last"
  }
}
output {
    elasticsearch {
    		hosts =&gt; "localhost:9200"
        index =&gt; "information"
        document_type =&gt; "article"
        document_id =&gt; "%{id}"
        action =&gt; "update"　 # 操作执行的动作,可选值有["index", "delete", "create", "update"]
        doc_as_upsert =&gt; true  #支持update模式
    }
}
				
				</pre>
			</div>
		</div>

		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.sync"></a>8.11.6. 解决数据不对称问题</h3></div></div></div>
			
			<p>jdbc-input-plugin 只能实现数据库的追加，对于 elasticsearch 增量写入，但经常jdbc源一端的数据库可能会做数据库删除或者更新操作。这样一来数据库与搜索引擎的数据库就出现了不对称的情况。</p>
			<p>当然你如果有开发团队可以写程序在删除或者更新的时候同步对搜索引擎操作。如果你没有这个能力，可以尝试下面的方法。</p>
			<p>这里有一个数据表 article , mtime 字段定义了 ON UPDATE CURRENT_TIMESTAMP 所以每次更新mtime的时间都会变化</p>
			<pre class="screen">
			
mysql&gt; desc article;
+-------------+--------------+------+-----+--------------------------------+-------+
| Field       | Type         | Null | Key | Default                        | Extra |
+-------------+--------------+------+-----+--------------------------------+-------+
| id          | int(11)      | NO   |     | 0                              |       |
| title       | mediumtext   | NO   |     | NULL                           |       |
| description | mediumtext   | YES  |     | NULL                           |       |
| author      | varchar(100) | YES  |     | NULL                           |       |
| source      | varchar(100) | YES  |     | NULL                           |       |
| content     | longtext     | YES  |     | NULL                           |       |
| status      | enum('Y','N')| NO   |     | 'N'                            |       |
| ctime       | timestamp    | NO   |     | CURRENT_TIMESTAMP              |       |
| mtime       | timestamp    | YES  |     | ON UPDATE CURRENT_TIMESTAMP    |       |
+-------------+--------------+------+-----+--------------------------------+-------+
7 rows in set (0.00 sec)
			
			</pre>
			<p>logstash 增加 mtime 的查询规则</p>
			<pre class="screen">
			
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "password"
    schedule =&gt; "* * * * *"	#定时cron的表达式,这里是每分钟执行一次
    statement =&gt; "select * from article where mtime &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "mtime"
    tracking_column_type =&gt; "timestamp" 
    record_last_run =&gt; true
    last_run_metadata_path =&gt; "/var/tmp/article-mtime.last"
  }
			
			
			</pre>
			<p>创建回收站表，这个事用于解决数据库删除，或者禁用 status = 'N' 这种情况的。</p>
			<pre class="screen">
			
CREATE TABLE `elasticsearch_trash` (
  `id` int(11) NOT NULL,
  `ctime` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
			
			</pre>
			<p>为 article 表创建触发器</p>
			<pre class="screen">
			
CREATE DEFINER=`dba`@`%` TRIGGER `article_BEFORE_UPDATE` BEFORE UPDATE ON `article` FOR EACH ROW
BEGIN
	-- 此处的逻辑是解决文章状态变为 N 的时候，需要将搜索引擎中对应的数据删除。
	IF NEW.status = 'N' THEN
		insert into elasticsearch_trash(id) values(OLD.id);
	END IF;
	-- 此处逻辑是修改状态到 Y 的时候，方式elasticsearch_trash仍然存在该文章ID，导致误删除。所以需要删除回收站中得回收记录。
    IF NEW.status = 'Y' THEN
		delete from elasticsearch_trash where id = OLD.id;
	END IF;
END

CREATE DEFINER=`dba`@`%` TRIGGER `article_BEFORE_DELETE` BEFORE DELETE ON `article` FOR EACH ROW
BEGIN
	-- 此处逻辑是文章被删除同事将改文章放入搜索引擎回收站。
	insert into elasticsearch_trash(id) values(OLD.id);
END
			
			</pre>
			<p>接下来我们需要写一个简单地 Shell 每分钟运行一次，从 elasticsearch_trash 数据表中取出数据，然后使用 curl 命令调用 elasticsearch restful 接口，删除被收回的数据。 </p>
		</div>
		
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="logstash.mapping"></a>8.11.7. 修改 Mapping</h3></div></div></div>
			
			<span style="color: red">&lt;paraf&gt;需求 Elasticsearch 时间格式 从ISO 8601 到 yyyy-MM-dd HH:mm:ss。首先停止 logstash&lt;/paraf&gt;</span>
			<pre class="screen">
			
systemctl stop logstash

rm -rf /var/tmp/article* 			
			
			</pre>
			<p>修改 /etc/logstash/conf.d/jdbc.conf 配置文件</p>
			<pre class="screen">
			
input {
  jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "123456"
    schedule =&gt; "* * * * *"
    statement =&gt; "select * from article where id &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "id"
    tracking_column_type =&gt; "numeric" 
    record_last_run =&gt; true
    last_run_metadata_path =&gt; "/var/tmp/article.last"
  }
jdbc {
    jdbc_driver_library =&gt; "/usr/share/java/mysql-connector-java.jar"
    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
    jdbc_connection_string =&gt; "jdbc:mysql://localhost:3306/cms"
    jdbc_user =&gt; "cms"
    jdbc_password =&gt; "123456"
    schedule =&gt; "* * * * *"	#定时cron的表达式,这里是每分钟执行一次
    statement =&gt; "select * from article where ctime &gt; :sql_last_value"
    use_column_value =&gt; true
    tracking_column =&gt; "ctime"
    tracking_column_type =&gt; "timestamp" 
    record_last_run =&gt; true
    last_run_metadata_path =&gt; "/var/tmp/article-ctime.last"
  }

}

filter {

    ruby {
        code =&gt; "event.set('ctime', event.get('[ctime]').time.localtime.strftime('%Y-%m-%d %H:%M:%S'))"
    }

    ruby {
        code =&gt; "event.set('mtime', event.get('[mtime]').time.localtime.strftime('%Y-%m-%d %H:%M:%S'))"
    }

}

output {
    elasticsearch {
    	hosts =&gt; "localhost:9200"
        index =&gt; "information"
        document_type =&gt; "article"
        document_id =&gt; "%{id}"
        action =&gt; "update"
        doc_as_upsert =&gt; true
    }
}
			
			
			</pre>
			<p>删除就的index，重新创建，并配置 mapping。</p>
			<pre class="programlisting">
			


curl -XDELETE http://localhost:9200/information

curl -XPUT http://localhost:9200/information
			
curl -XPOST http://localhost:9200/information/article/_mapping -d'
{
        "properties": {
            "title": {
                "type": "text",
                "analyzer": "ik_max_word",
                "search_analyzer": "ik_max_word"
            },
            "description": {
                "type": "text",
                "analyzer": "ik_max_word",
                "search_analyzer": "ik_max_word"
            },
            "content": {
                "type": "text",
                "analyzer": "ik_max_word",
                "search_analyzer": "ik_max_word"
            },
            "ctime": {
               "type":   "date",
               "format": "yyyy-MM-dd HH:mm:ss"
           	},
 			"mtime": {
               "type":   "date",
               "format": "yyyy-MM-dd HH:mm:ss"
           	}
        }
}'

curl "http://localhost:9200/information/article/_mapping?pretty"
			
			</pre>
			<p>启动 logstash 重新复制数据。</p>
			<pre class="screen">
			
rm -rf /var/log/logstash/*
systemctl start logstash			
			
			</pre>
			
		</div>
		
	</div><div xmlns="" id="disqus_thread"></div><script xmlns="">

var disqus_config = function () {
this.page.url = "http://www.netkiller.cn";  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'netkiller'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//netkiller.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script><noscript xmlns="">Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><br xmlns="" /><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="example.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="install.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">8.10. Example </td><td width="20%" align="center"><a accesskey="h" href="../../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 8.12. 安装 Elasticsearch 2.3</td></tr></table></div><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11694057-1', 'auto');
  ga('send', 'pageview');

</script><script xmlns="" async="async">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script xmlns="" async="async">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><script xmlns="" type="text/javascript" src="/js/q.js" async="async"></script></body></html>